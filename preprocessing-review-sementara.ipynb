{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Install Library","metadata":{}},{"cell_type":"code","source":"# utama\nimport pandas as pd\nimport numpy as np\nfrom textblob import Word\n\n# preprocessing\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import wordnet\nfrom collections import Counter\nfrom nltk.tokenize import sent_tokenize\n\n# data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# model building\nfrom sklearn import svm\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import KFold\n\n# model evaluation\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import train_test_split\n\n# lainnya\nfrom numpy import array\nfrom scipy.sparse import csr_matrix, coo_matrix, hstack\nfrom numpy import mean\nfrom nltk.corpus import words\nimport time\nimport csv\nimport os\nfrom sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2022-12-15T03:55:46.871903Z","iopub.execute_input":"2022-12-15T03:55:46.872806Z","iopub.status.idle":"2022-12-15T03:55:46.883585Z","shell.execute_reply.started":"2022-12-15T03:55:46.872760Z","shell.execute_reply":"2022-12-15T03:55:46.882013Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Prepare Contraction and Slang Words","metadata":{}},{"cell_type":"code","source":"# masukan path contraction dan slang words\n\ncontraction_words = pd.read_csv('../input/contraction/contraction_words.csv', header=None, index_col=0, squeeze=True).to_dict()\nslang_words = pd.read_csv('../input/slangs/slang_words.csv', header=None, index_col=0, squeeze=True).to_dict()","metadata":{"execution":{"iopub.status.busy":"2022-12-15T04:06:30.305768Z","iopub.execute_input":"2022-12-15T04:06:30.306825Z","iopub.status.idle":"2022-12-15T04:06:30.311714Z","shell.execute_reply.started":"2022-12-15T04:06:30.306776Z","shell.execute_reply":"2022-12-15T04:06:30.310450Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Example Data","metadata":{}},{"cell_type":"code","source":"# masukan path csv nya\n\nexample_data = pd.read_csv('../input/reviews/example-data.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Custom Function","metadata":{}},{"cell_type":"code","source":"def data_labeling(helpful_vote, total_vote):\n    if total_vote < 10:\n        return 'tidak bermanfaat'\n    else:\n        ratio_helpfulness = helpful_vote/total_vote\n        if ratio_helpfulness > 0.6:\n            return 'bermanfaat'\n        else:\n            return 'tidak bermanfaat'\n\ndef second_cleansing(text):\n    text = str(text)\n    text = text.lower()\n    text = re.sub(r\"http\\S+\", ' ', text) \n    text = re.sub(r\"www\\S+\", ' ', text) \n    text = re.sub(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});', ' ', text) # match html tags\n    text = expand_words(text, contraction_words) \n    text = expand_words(text, slang_words)\n    text = re.sub(r'[^a-z\\s]', ' ', text) # match string a-z only (remove punctuation, symbol, and number)\n    text = re.sub(r'\\s\\s+', ' ', text) # optional => match excess whitespace \n    return text\n\ndef expand_words(sentence, expansion_word):\n    sentence = sentence.split()\n    index_replace = []\n    replacement_word = []\n    for index, value in enumerate(sentence):        \n        for key in expansion_word:\n            if value == key:\n                index_replace.append(index)\n                replacement_word.append(expansion_word[key])\n                break\n    for index, value_index in enumerate(index_replace):\n        sentence[value_index] = replacement_word[index]\n    return ' '.join(sentence)\n\ndef stopword(sentence):\n    string = [i for i in sentence.split() if i not in stopwords.words('english')]\n    return ' '.join(string)\n\nwl = WordNetLemmatizer()\ndef get_wordnet_pos(tag):\n    if tag.startswith('J'):\n        return wordnet.ADJ\n    elif tag.startswith('V'):\n        return wordnet.VERB\n    elif tag.startswith('N'):\n        return wordnet.NOUN\n    elif tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN\n\ndef lemmatizer(sentence):\n    word_pos_tags = nltk.pos_tag(word_tokenize(sentence)) # get position tag\n    word = [wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # map the position tag and lemmatize the word/token\n    return ' '.join(word)\n\n# --------------- spelling correction ---------------\nword_list = words.words() \ndef word_check(sentence):\n    final_word_list = []\n    for word in sentence.split():\n        if word in word_list:\n            final_word_list.append(word)\n        else:\n            corrected_word = spelling_check(word)\n            final_word_list.append(corrected_word)\n    return ' '.join(final_word_list) \n\ndef spelling_check(word):\n    word = Word(word)\n    result = word.spellcheck()\n    if result[0][1] == 0:\n        corrected_word = spelling_corrector(word)\n        return corrected_word\n    else:\n        return result[0][0]\n        \ndef spelling_corrector(word):\n    elongated_word = bool(re.search(r'(.)\\1{2,}', word))\n    if elongated_word:\n        temp_word = word \n        while bool(re.search(r'(.)\\1{2,}', temp_word)):\n            temp = list(temp_word)\n            char = re.search(r'(.)\\1{2,}', temp_word)\n            temp[char.start():(char.end() - 1)] = ''\n            string = \"\".join(temp)\n            word = Word(string)\n            result = word.spellcheck()\n            if result[0][1] != 0:\n                return result[0][0]\n                break\n            else:\n                temp_word = string\n                if bool(re.search(r'(.)\\1{2,}', temp_word)):\n                    continue\n                else:\n                    return word\n                    break\n    else:\n        return word\n# --------------- spelling correction ---------------\n\ndef final_preprocess(sentence):\n    return word_check(lemmatizer(stopword(second_cleansing(sentence))))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# one review\n\nsecond_cleansing(\"\"\" Very good, inexpensive brush! Bought 5 for my wife &amp; I. 4 lasted 20 months. On the last one &amp; ready to re-order. Can't beat the price https://www.youtube.com/watch?v=nVHP49g5IPQ. \"\"\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# multiple review\n\nmultiple_review = pd.DataFrame({'teks': [\n    \"\"\" Very good, inexpensive brush! Bought 5 for my wife &amp; I. 4 lasted 20 months. On the last one &amp; ready to re-order. Can't beat the price. \"\"\", \n    \"\"\" AMMMAAAZZZIIINNNGGGGG Don't think twice just buy it. It's amazing how even after the first use what a difference it makes. I love this stuff :) \"\"\",\n    \"\"\" Who pays 4 dollars more for a $20 gift card?<br />What store doesn't sell gift cards that the extra 4 dollars sounds like a good idea? \"\"\",\n    \"\"\" Fun game, fast delivery.<br />No problems or complaints.  Nice aqnd fast delivery.  Game is in excellent condition.  Brand New I believe. \"\"\",\n]})\n\n\nsatu = multiple_review.teks.apply(lambda x: lowercase(x))\ndua = multiple_review.teks.apply(lambda x: remove_html(lowercase(x)) )\ntiga = multiple_review.teks.apply(lambda x: remove_noise(remove_html(lowercase(x))))\n\nprint(satu)\nprint(dua)\nprint(tiga)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T03:11:19.427498Z","iopub.execute_input":"2022-12-15T03:11:19.428081Z","iopub.status.idle":"2022-12-15T03:11:19.450376Z","shell.execute_reply.started":"2022-12-15T03:11:19.427975Z","shell.execute_reply":"2022-12-15T03:11:19.448815Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# use dataset\n\nexample_data.loc[:, 'clean_review'] = example_data.apply(lambda x: final_preprocess(x.review_body), axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T04:04:08.832570Z","iopub.execute_input":"2022-12-15T04:04:08.833112Z","iopub.status.idle":"2022-12-15T04:04:08.838778Z","shell.execute_reply.started":"2022-12-15T04:04:08.833046Z","shell.execute_reply":"2022-12-15T04:04:08.837793Z"},"trusted":true},"execution_count":5,"outputs":[]}]}